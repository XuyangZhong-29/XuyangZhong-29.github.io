---
title: "Sparse-PGD: A Unified Framework for Sparse Adversarial Perturbation Generation"
collection: publications
category: manuscripts
permalink: /publication/sparse_pgd_tpami
excerpt: '**Xuyang Zhong**, Chen Liu'
date: 2025-11-05
venue: 'IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)'
paperurl: 'https://xuyang-zhong.github.io/files/sparse_pgd_tpami.pdf'
---
This work studies sparse adversarial perturbations, including both unstructured and structured ones. We propose a framework based on a white-box PGD-like attack method named Sparse-PGD to effectively and efficiently generate such perturbations. Furthermore, we combine Sparse-PGD with a black-box attack to comprehensively and more reliably evaluate the models' robustness against unstructured and structured sparse adversarial perturbations. Moreover, the efficiency of Sparse-PGD enables us to conduct adversarial training to build robust models against various sparse perturbations. Extensive experiments demonstrate that our proposed attack algorithm exhibits strong performance in different scenarios. More importantly, compared with other robust models, our adversarially trained model demonstrates state-of-the-art robustness against various sparse attacks. Codes are available at [https://github.com/CityU-MLO/sPGD](https://github.com/CityU-MLO/sPGD).
